{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CBX8 LD matrix from 1000 Genomes (GRCh38)\n",
        "\n",
        "This notebook reads `output/CBX8_variants.vcf`, downloads the 1000G sample panel, ",
        "pulls only the chr17 region spanning those variants from the 1000 Genomes GRCh38 VCF, ",
        "and builds an LD correlation matrix (R) for EUR samples.\n",
        "\n",
        "Outputs:\n",
        "- `output/CBX8_LD_R.csv` (LD matrix)\n",
        "- `output/CBX8_LD_R.npy` (binary matrix)\n",
        "- `output/CBX8_LD_variant_order.tsv` (variant order)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import importlib.util\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def ensure_pkg(name):\n",
        "    if importlib.util.find_spec(name) is None:\n",
        "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', name])\n",
        "\n",
        "for pkg in ['numpy', 'pysam']:\n",
        "    ensure_pkg(pkg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "root = Path.cwd()\n",
        "if root.name == 'vignettes':\n",
        "    root = root.parent\n",
        "elif not (root / 'output').exists() and (root / 'vignettes').exists():\n",
        "    # Fallback if notebook is launched from a subdir\n",
        "    root = root\n",
        "\n",
        "data_dir = root / 'data'\n",
        "output_dir = root / 'output'\n",
        "data_dir.mkdir(parents=True, exist_ok=True)\n",
        "output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "vcf_path = output_dir / 'CBX8_variants.vcf'\n",
        "if not vcf_path.exists():\n",
        "    raise FileNotFoundError(f'Missing input VCF: {vcf_path}')\n",
        "\n",
        "variants = []\n",
        "with vcf_path.open() as f:\n",
        "    for line in f:\n",
        "        if line.startswith('#'):\n",
        "            continue\n",
        "        fields = line.rstrip('\\n').split('\\t')\n",
        "        if len(fields) < 5:\n",
        "            continue\n",
        "        chrom, pos, vid, ref, alt = fields[:5]\n",
        "        variants.append({\n",
        "            'chrom': chrom,\n",
        "            'pos': int(pos),\n",
        "            'id': vid,\n",
        "            'ref': ref,\n",
        "            'alt': alt.split(',')[0],\n",
        "        })\n",
        "\n",
        "if not variants:\n",
        "    raise ValueError('No variants found in input VCF.')\n",
        "\n",
        "chroms = sorted({v['chrom'] for v in variants})\n",
        "min_pos = min(v['pos'] for v in variants)\n",
        "max_pos = max(v['pos'] for v in variants)\n",
        "\n",
        "print(f'Loaded {len(variants)} variants on {chroms}')\n",
        "print(f'Region: {chroms[0]}:{min_pos}-{max_pos}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "\n",
        "panel_url = (\n",
        "    'https://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/'\n",
        "    'integrated_call_samples_v3.20130502.ALL.panel'\n",
        ")\n",
        "panel_path = data_dir / 'integrated_call_samples_v3.20130502.ALL.panel'\n",
        "\n",
        "if not panel_path.exists():\n",
        "    print(f'Downloading panel to {panel_path}')\n",
        "    urllib.request.urlretrieve(panel_url, panel_path)\n",
        "\n",
        "eur_samples = []\n",
        "with panel_path.open() as f:\n",
        "    header = f.readline()\n",
        "    for line in f:\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            continue\n",
        "        fields = line.split()\n",
        "        if len(fields) < 3:\n",
        "            continue\n",
        "        sample, pop, super_pop = fields[:3]\n",
        "        if super_pop == 'EUR':\n",
        "            eur_samples.append(sample)\n",
        "\n",
        "print(f'EUR samples in panel: {len(eur_samples)}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pysam\n",
        "\n",
        "base_url = (\n",
        "    'https://ftp.1000genomes.ebi.ac.uk/vol1/ftp/'\n",
        "    'data_collections/1000_genomes_project/release/'\n",
        "    '20190312_biallelic_SNV_and_INDEL'\n",
        ")\n",
        "\n",
        "chrom_no_chr = chroms[0].replace('chr', '')\n",
        "vcf_url = (\n",
        "    f'{base_url}/ALL.chr{chrom_no_chr}.'\n",
        "    'shapeit2_integrated_snvindels_v2a_27022019.GRCh38.phased.vcf.gz'\n",
        ")\n",
        "\n",
        "vcf_in = pysam.VariantFile(vcf_url)\n",
        "contigs = set(vcf_in.header.contigs)\n",
        "chrom_with_chr = f'chr{chrom_no_chr}'\n",
        "\n",
        "if chroms[0] in contigs:\n",
        "    fetch_chrom = chroms[0]\n",
        "elif chrom_with_chr in contigs:\n",
        "    fetch_chrom = chrom_with_chr\n",
        "elif chrom_no_chr in contigs:\n",
        "    fetch_chrom = chrom_no_chr\n",
        "else:\n",
        "    raise ValueError(f'Chromosome not found in VCF contigs: {chroms[0]}')\n",
        "\n",
        "vcf_samples = list(vcf_in.header.samples)\n",
        "eur_set = set(eur_samples)\n",
        "sample_names = [s for s in vcf_samples if s in eur_set]\n",
        "if not sample_names:\n",
        "    raise ValueError('No EUR samples from the panel were found in the VCF header.')\n",
        "\n",
        "print(f'EUR samples used: {len(sample_names)}')\n",
        "\n",
        "key_to_index = {}\n",
        "for idx, v in enumerate(variants):\n",
        "    chrom_key = v['chrom']\n",
        "    chrom_no_chr = chrom_key.replace('chr', '')\n",
        "    chrom_with_chr = f'chr{chrom_no_chr}'\n",
        "    for ck in {chrom_key, chrom_no_chr, chrom_with_chr}:\n",
        "        key_to_index[(ck, v['pos'], v['ref'], v['alt'])] = idx\n",
        "\n",
        "G = np.full((len(variants), len(sample_names)), np.nan, dtype=np.float32)\n",
        "\n",
        "start0 = min_pos - 1\n",
        "end0 = max_pos\n",
        "hits = 0\n",
        "for rec in vcf_in.fetch(fetch_chrom, start0, end0):\n",
        "    if not rec.alts:\n",
        "        continue\n",
        "    alt = rec.alts[0]\n",
        "    key = (rec.chrom, rec.pos, rec.ref, alt)\n",
        "    idx = key_to_index.get(key)\n",
        "    if idx is None:\n",
        "        continue\n",
        "    hits += 1\n",
        "    for j, s in enumerate(sample_names):\n",
        "        gt = rec.samples[s].get('GT')\n",
        "        if gt is None or None in gt:\n",
        "            continue\n",
        "        if -1 in gt:\n",
        "            continue\n",
        "        G[idx, j] = gt[0] + gt[1]\n",
        "\n",
        "print(f'Matched variants in 1000G: {hits} / {len(variants)}')\n",
        "\n",
        "found_mask = ~np.isnan(G).all(axis=1)\n",
        "if not found_mask.all():\n",
        "    missing = [variants[i]['id'] for i, ok in enumerate(found_mask) if not ok]\n",
        "    print(f'Missing variants not found in 1000G VCF: {len(missing)}')\n",
        "    print('Example missing IDs:', missing[:10])\n",
        "    G = G[found_mask]\n",
        "    variants = [v for v, ok in zip(variants, found_mask) if ok]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "G_mean = np.nanmean(G, axis=1, keepdims=True)\n",
        "G_filled = np.where(np.isnan(G), G_mean, G)\n",
        "X = G_filled - G_mean\n",
        "ddof = 1 if G.shape[1] > 1 else 0\n",
        "stds = X.std(axis=1, ddof=ddof, keepdims=True)\n",
        "stds[stds == 0] = np.nan\n",
        "X = X / stds\n",
        "X = np.nan_to_num(X, nan=0.0)\n",
        "R = (X @ X.T) / max(G.shape[1] - 1, 1)\n",
        "np.fill_diagonal(R, 1.0)\n",
        "\n",
        "variant_labels = [v['id'] for v in variants]\n",
        "\n",
        "output_csv = output_dir / 'CBX8_LD_R.csv'\n",
        "with output_csv.open('w', newline='') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(['variant'] + variant_labels)\n",
        "    for label, row in zip(variant_labels, R):\n",
        "        writer.writerow([label] + [f'{x:.6g}' for x in row])\n",
        "\n",
        "np.save(output_dir / 'CBX8_LD_R.npy', R)\n",
        "\n",
        "order_path = output_dir / 'CBX8_LD_variant_order.tsv'\n",
        "with order_path.open('w', newline='') as f:\n",
        "    writer = csv.writer(f, delimiter='\t')\n",
        "    writer.writerow(['index', 'id', 'chrom', 'pos', 'ref', 'alt'])\n",
        "    for i, v in enumerate(variants):\n",
        "        writer.writerow([i, v['id'], v['chrom'], v['pos'], v['ref'], v['alt']])\n",
        "\n",
        "print('Wrote:', output_csv)\n",
        "print('Wrote:', order_path)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}